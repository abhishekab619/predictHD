{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0pB7ANKA-2S7"
      },
      "outputs": [],
      "source": [
        "#CAE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, UpSampling1D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfxHMIDn-_Lp",
        "outputId": "d1272d3d-a253-4584-88fa-1d25a1e507ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJHOlffY_Glc"
      },
      "outputs": [],
      "source": [
        "def load_data(filename):\n",
        "    df = pd.read_parquet(f'/content/drive/MyDrive/BB_Normalized_Monthly_Final/{filename}')\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "    df = df.dropna(subset=['date'])\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_cols.remove('failure')\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols].values)\n",
        "    return df, numeric_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzfNtuyO_MYN"
      },
      "outputs": [],
      "source": [
        "data, numeric_cols = load_data('vectorized_combined_data_minus_183.parquet')\n",
        "data_numpy = np.array(data[numeric_cols], dtype=np.float32)\n",
        "data_numpy = data_numpy.reshape(data_numpy.shape[0], data_numpy.shape[1], 1)\n",
        "labels = data['failure'].apply(lambda x: 1 if x > 0 else 0).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_numpy, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "X_train_res = X_train_res.reshape(X_train_res.shape[0], X_train.shape[1], X_train.shape[2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waNhbMeF_Un2"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=(X_train_res.shape[1], 1))\n",
        "x = Conv1D(16, 3, activation='relu', padding='same')(input_layer)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 3, activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 3, activation='relu', padding='same')(encoded)\n",
        "x = UpSampling1D(2)(x)\n",
        "x = Conv1D(16, 3, activation='relu', padding='same')(x)\n",
        "x = UpSampling1D(2)(x)\n",
        "decoded = Conv1D(1, 3, activation='sigmoid', padding='same')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkC-SVM0_jTY",
        "outputId": "6e6c5a7a-17cb-4e34-a871-68800924aa6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 159994/1276234 [==>...........................] - ETA: 1:16:43 - loss: 92.1761\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            " 319990/1276234 [======>.......................] - ETA: 1:05:46 - loss: 91.4823\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            " 479993/1276234 [==========>...................] - ETA: 54:47 - loss: 91.9286\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            " 639998/1276234 [==============>...............] - ETA: 43:46 - loss: 91.7651\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            " 799997/1276234 [=================>............] - ETA: 32:45 - loss: 91.8615\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            " 959989/1276234 [=====================>........] - ETA: 21:45 - loss: 91.9013\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            "1119996/1276234 [=========================>....] - ETA: 10:44 - loss: 92.0259\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_01.ckpt\n",
            "1276234/1276234 [==============================] - 5636s 4ms/step - loss: 92.0531 - val_loss: 0.9203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.0001), loss='mse')\n",
        "checkpoint_path = \"/content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/autoencoder_{epoch:02d}.ckpt\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_freq=5000*32)\n",
        "autoencoder.fit(X_train_res, X_train_res, epochs=1, batch_size=32, validation_data=(X_val, X_val), callbacks=[checkpoint_callback])\n",
        "autoencoder.save('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/autoencoder.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiekxcGeBQxf",
        "outputId": "6e6b3dc1-e644-4b30-b55a-926ec8afd603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20, 1)]           0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 20, 16)            64        \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 10, 16)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 10, 8)             392       \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 5, 8)              0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 5, 8)              200       \n",
            "                                                                 \n",
            " up_sampling1d_2 (UpSamplin  (None, 10, 8)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_8 (Conv1D)           (None, 10, 16)            400       \n",
            "                                                                 \n",
            " up_sampling1d_3 (UpSamplin  (None, 20, 16)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_9 (Conv1D)           (None, 20, 1)             49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1105 (4.32 KB)\n",
            "Trainable params: 1105 (4.32 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "autoencoder = load_model('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/autoencoder.h5')\n",
        "\n",
        "autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNz1APS_BaLJ"
      },
      "outputs": [],
      "source": [
        "#CNN\n",
        "\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFgT8lVYBbEk"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#tf.data API\n",
        "def predict_with_tfdata(model, data, batch_size=256):\n",
        "    #TensorFlow dataset object from the numpy array\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(data).batch(batch_size)\n",
        "\n",
        "    #prediction loop\n",
        "    predictions = []\n",
        "    for batch in dataset:\n",
        "        batch_predictions = model.predict_on_batch(batch)  #memory usage optimization\n",
        "        predictions.append(batch_predictions)\n",
        "\n",
        "    #concatenate all batch predictions\n",
        "    return np.vstack(predictions)\n",
        "\n",
        "#load autoencoder\n",
        "autoencoder = load_model('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/autoencoder.h5')\n",
        "\n",
        "#extract and predict using the encoder part from the autoencoder model\n",
        "encoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer('max_pooling1d_3').output)\n",
        "encoded_train = predict_with_tfdata(encoder, X_train_res)\n",
        "encoded_val = predict_with_tfdata(encoder, X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwy5JFPRBd_Z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Conv1D(32, 3, activation='relu', input_shape=encoder.output_shape[1:]),\n",
        "    MaxPooling1D(2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqbZ5yQABgpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e6eed6-8a10-4ff3-8339-59ab9ffa4eff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 159986/1276234 [==>...........................] - ETA: 1:00:03 - loss: 0.5612 - accuracy: 0.6730\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            " 319992/1276234 [======>.......................] - ETA: 51:30 - loss: 0.5585 - accuracy: 0.6745\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            " 479991/1276234 [==========>...................] - ETA: 42:49 - loss: 0.5569 - accuracy: 0.6753\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            " 639989/1276234 [==============>...............] - ETA: 34:11 - loss: 0.5557 - accuracy: 0.6758\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            " 799987/1276234 [=================>............] - ETA: 25:35 - loss: 0.5549 - accuracy: 0.6760\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            " 959988/1276234 [=====================>........] - ETA: 16:59 - loss: 0.5541 - accuracy: 0.6764\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            "1119995/1276234 [=========================>....] - ETA: 8:23 - loss: 0.5535 - accuracy: 0.6765\n",
            "Epoch 1: saving model to /content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_01.ckpt\n",
            "1276234/1276234 [==============================] - 4465s 3ms/step - loss: 0.5530 - accuracy: 0.6767 - val_loss: 0.5262 - val_accuracy: 0.8683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "cnn_model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "checkpoint_path = \"/content/drive/MyDrive/BB_Normalized_Monthly_Final/Checkpoints/CNN_{epoch:02d}.ckpt\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_freq=5000*32)\n",
        "cnn_model.fit(encoded_train, y_train_res, epochs=1, batch_size=32, validation_data=(encoded_val, y_val), callbacks=[checkpoint_callback])\n",
        "cnn_model.save('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/cnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqIc0JDaBji9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c469d4f0-1b39-4bac-a540-6c27df7bcf61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_5 (Conv1D)           (None, 3, 32)             800       \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 1, 32)             0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                2112      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2977 (11.63 KB)\n",
            "Trainable params: 2977 (11.63 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "cnn_model = load_model('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/cnn_model.h5')\n",
        "\n",
        "cnn_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m7MU7EdgHyqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "9dtYCZYaHyoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "#tokenizer and model for mixtral from huggingface\n",
        "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "api_token = \"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\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=api_token)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, use_auth_token=api_token, device_map=\"auto\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763,
          "referenced_widgets": [
            "51a10bf4aac848dab612b7f2da457373",
            "66d0764feee2449a983bb8b7ec57c1e0",
            "0b59cce91a264701aed31033bb9dc4f6",
            "5ef490c3108a4b75867ff9c3c8a30105",
            "585d1fc3930f4b14ab30e819cba050d3",
            "8bb3f6852f8c4b179e36a551ea8f4c93",
            "afa96929da884ed2bc0146921147de5b",
            "2e554f6b0e884b369eac70a8d1640c06",
            "bea00ce11c8f445b84a22df760ea79ec",
            "9931f22f4c5c4cf0b7cf8fb2386ed8c7",
            "e7816d2bf05e4c429eb8c430e232311f"
          ]
        },
        "id": "7kjCC6gnHyl8",
        "outputId": "c17fc431-b150-4d67-ae0e-8c3b42cf1e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51a10bf4aac848dab612b7f2da457373"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#load and preprocess data\n",
        "def load_data(filename):\n",
        "    df = pd.read_parquet(f'/content/drive/MyDrive/BB_Normalized_Monthly_Final/{filename}')\n",
        "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
        "    df = df.dropna(subset=['date'])\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "    numeric_cols.remove('failure')\n",
        "    scaler = StandardScaler()\n",
        "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols].values)\n",
        "    return df, numeric_cols\n",
        "\n",
        "#load and preprocess the data\n",
        "data, numeric_cols = load_data('vectorized_combined_data_minus_183.parquet')\n",
        "data_numpy = np.array(data[numeric_cols], dtype=np.float32)\n",
        "data_numpy = data_numpy.reshape(data_numpy.shape[0], data_numpy.shape[1], 1)\n",
        "labels = data['failure'].apply(lambda x: 1 if x > 0 else 0).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_numpy, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "sm = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = sm.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
        "X_train_res = X_train_res.reshape(X_train_res.shape[0], X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "#load CNN model\n",
        "cnn_model = load_model('/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/cnn_model.h5')\n"
      ],
      "metadata": {
        "id": "V9bxlsozHyjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<H1>This is where the runtime kept crashing due to the system running out of RAM</H1>"
      ],
      "metadata": {
        "id": "zRYnEqVa0xwa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3-_sElTHyhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lng9W6WkHx_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MZkQ4sgI1UUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5UzoaTSB1UOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMj0435wBqQD"
      },
      "outputs": [],
      "source": [
        "#dummy transformer created based on Mixtral-8x7B-Instruct-v0.1 config\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "class DummyMixtralModel(tf.keras.layers.Layer):\n",
        "    def __init__(self, config):\n",
        "        super(DummyMixtralModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(config['hidden_size'], activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = []\n",
        "        for batch in tf.data.Dataset.from_tensor_slices(inputs).batch(1024):\n",
        "            x = self.dense1(batch)\n",
        "            x = self.dense2(x)\n",
        "            outputs.append(x)\n",
        "        return tf.concat(outputs, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0yF-9zfBzF1"
      },
      "outputs": [],
      "source": [
        "transformer_config = {\n",
        "    \"hidden_size\": 1024,\n",
        "    \"num_hidden_layers\": 8,\n",
        "    \"num_attention_heads\": 16,\n",
        "    \"intermediate_size\": 4096,\n",
        "    \"hidden_act\": \"gelu\",\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-12,\n",
        "    \"pad_token_id\": 0,\n",
        "    \"architectures\": [\"TFAutoModel\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lb0JYIjB3yj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb78bc7-808f-45d9-a4ef-da163b90f70c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6648/6648 [==============================] - 8s 1ms/step\n",
            "Transformer Outputs: [[[-0.529158  ]\n",
            "  [-0.62196606]\n",
            "  [-0.8002789 ]\n",
            "  [-0.634541  ]\n",
            "  [-0.61245114]]\n",
            "\n",
            " [[-0.82017374]\n",
            "  [-0.7326404 ]\n",
            "  [-0.8002789 ]\n",
            "  [-0.634541  ]\n",
            "  [-0.61245114]]\n",
            "\n",
            " [[-0.714473  ]\n",
            "  [-0.7004396 ]\n",
            "  [-0.76818305]\n",
            "  [-0.634541  ]\n",
            "  [-0.61245114]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.763984  ]\n",
            "  [-0.6818883 ]\n",
            "  [-0.70562947]\n",
            "  [-0.6345408 ]\n",
            "  [-0.6124512 ]]\n",
            "\n",
            " [[-0.6872704 ]\n",
            "  [-0.6459064 ]\n",
            "  [-0.6040093 ]\n",
            "  [-0.6345408 ]\n",
            "  [-0.6124512 ]]\n",
            "\n",
            " [[-0.7696945 ]\n",
            "  [-0.6960386 ]\n",
            "  [-0.70562947]\n",
            "  [-0.6345408 ]\n",
            "  [-0.6124512 ]]]\n"
          ]
        }
      ],
      "source": [
        "dummy_transformer = DummyMixtralModel(transformer_config)\n",
        "encoded_test = encoder.predict(X_test, batch_size=1024)\n",
        "transformer_inputs = tf.convert_to_tensor(encoded_test)\n",
        "transformer_outputs = dummy_transformer(transformer_inputs)\n",
        "print(\"Transformer Outputs:\", transformer_outputs.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0W9GWOGB7cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01577fec-21a2-4b4b-f97b-40f0b08048cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 512)]             0         \n",
            "                                                                 \n",
            " dummy_mixtral_model_4 (Dum  (None, 1)                 526337    \n",
            " myMixtralModel)                                                 \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 526337 (2.01 MB)\n",
            "Trainable params: 526337 (2.01 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class DummyMixtralModel(tf.keras.layers.Layer):\n",
        "    def __init__(self, config):\n",
        "        super(DummyMixtralModel, self).__init__()\n",
        "        self.dense1 = tf.keras.layers.Dense(config['hidden_size'], activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.dense1(inputs)\n",
        "        return self.dense2(x)\n",
        "\n",
        "transformer_config = {\n",
        "    \"hidden_size\": 1024,\n",
        "    \"num_hidden_layers\": 8,\n",
        "    \"num_attention_heads\": 16,\n",
        "    \"intermediate_size\": 4096,\n",
        "    \"hidden_act\": \"gelu\",\n",
        "    \"hidden_dropout_prob\": 0.1,\n",
        "    \"attention_probs_dropout_prob\": 0.1,\n",
        "    \"max_position_embeddings\": 512,\n",
        "    \"type_vocab_size\": 2,\n",
        "    \"initializer_range\": 0.02,\n",
        "    \"layer_norm_eps\": 1e-12,\n",
        "    \"pad_token_id\": 0,\n",
        "    \"architectures\": [\"TFAutoModel\"]\n",
        "}\n",
        "\n",
        "# Instantiate the dummy transformer model\n",
        "dummy_transformer_layer = DummyMixtralModel(transformer_config)\n",
        "\n",
        "# Create a functional model to include the layer\n",
        "inputs = tf.keras.Input(shape=(512,))\n",
        "outputs = dummy_transformer_layer(inputs)\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Now you can print the summary of the entire model\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/dummy_transformer_model'\n",
        "\n",
        "model.save(save_path, save_format='tf')\n",
        "\n",
        "model.save(save_path + '.h5', save_format='h5')\n",
        "\n",
        "print(f\"Model saved successfully at {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSgtAcFJxQRI",
        "outputId": "1ab72a34-0d05-4045-f24d-e5264ecc591b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at /content/drive/MyDrive/BB_Normalized_Monthly_Final/Models/dummy_transformer_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OW3rltXyH5M",
        "outputId": "79cdbd5b-2d2b-45a2-e6d9-70b72dddfc26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oVtKkpvQyH27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sy3jLyLoyHwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vNyy9GLqyHtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VNwITyUHyHmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we wrote this to keep our runtime active\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "print(\"Script started at:\", start_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        current_time = datetime.datetime.now()\n",
        "        elapsed_time = current_time - start_time\n",
        "        print(\"DELETE THIS EVERY 75 seconds, this text is here just to block A100\")\n",
        "        print(\"Current time:\", current_time.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "        print(\"Running for:\", str(elapsed_time))\n",
        "        time.sleep(75)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Stopped by user.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIYf-s4JRkZw",
        "outputId": "cca2f630-cd4e-47e7-a7f1-441dade534d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Script started at: 2024-05-14 16:03:41\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:03:41\n",
            "Running for: 0:00:00.000235\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:04:56\n",
            "Running for: 0:01:15.075394\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:06:11\n",
            "Running for: 0:02:30.150828\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:07:26\n",
            "Running for: 0:03:45.227028\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:08:41\n",
            "Running for: 0:05:00.299693\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:09:56\n",
            "Running for: 0:06:15.375018\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:11:11\n",
            "Running for: 0:07:30.386177\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:12:26\n",
            "Running for: 0:08:45.461608\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:13:41\n",
            "Running for: 0:10:00.537688\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:14:56\n",
            "Running for: 0:11:15.579117\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:16:11\n",
            "Running for: 0:12:30.610759\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:17:26\n",
            "Running for: 0:13:45.611604\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:18:41\n",
            "Running for: 0:15:00.670703\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:19:56\n",
            "Running for: 0:16:15.699552\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:21:12\n",
            "Running for: 0:17:30.743561\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:22:27\n",
            "Running for: 0:18:45.774504\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:23:42\n",
            "Running for: 0:20:00.803692\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:24:57\n",
            "Running for: 0:21:15.808782\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:26:12\n",
            "Running for: 0:22:30.884255\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:27:27\n",
            "Running for: 0:23:45.959703\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:28:42\n",
            "Running for: 0:25:01.002114\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:29:57\n",
            "Running for: 0:26:16.079131\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:31:12\n",
            "Running for: 0:27:31.156161\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:32:27\n",
            "Running for: 0:28:46.231923\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:33:42\n",
            "Running for: 0:30:01.235718\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:34:57\n",
            "Running for: 0:31:16.243711\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:36:12\n",
            "Running for: 0:32:31.319243\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:37:27\n",
            "Running for: 0:33:46.396035\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:38:42\n",
            "Running for: 0:35:01.471426\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:39:57\n",
            "Running for: 0:36:16.546883\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:41:12\n",
            "Running for: 0:37:31.555867\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:42:27\n",
            "Running for: 0:38:46.632392\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:43:42\n",
            "Running for: 0:40:01.707869\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:44:58\n",
            "Running for: 0:41:16.784677\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:46:13\n",
            "Running for: 0:42:31.835523\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:47:28\n",
            "Running for: 0:43:46.875844\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:48:43\n",
            "Running for: 0:45:01.952007\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:49:58\n",
            "Running for: 0:46:17.008692\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:51:13\n",
            "Running for: 0:47:32.083705\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:52:28\n",
            "Running for: 0:48:47.159443\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:53:43\n",
            "Running for: 0:50:02.235926\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:54:58\n",
            "Running for: 0:51:17.310680\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:56:13\n",
            "Running for: 0:52:32.386392\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:57:28\n",
            "Running for: 0:53:47.461835\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:58:43\n",
            "Running for: 0:55:02.537335\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 16:59:58\n",
            "Running for: 0:56:17.614366\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:01:13\n",
            "Running for: 0:57:32.691399\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:02:28\n",
            "Running for: 0:58:47.708742\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:03:44\n",
            "Running for: 1:00:02.783673\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:04:59\n",
            "Running for: 1:01:17.828123\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:06:14\n",
            "Running for: 1:02:32.832920\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:07:29\n",
            "Running for: 1:03:47.875714\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:08:44\n",
            "Running for: 1:05:02.952487\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:09:59\n",
            "Running for: 1:06:18.027683\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:11:14\n",
            "Running for: 1:07:33.103175\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:12:29\n",
            "Running for: 1:08:48.179807\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:13:44\n",
            "Running for: 1:10:03.252918\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:14:59\n",
            "Running for: 1:11:18.329848\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:16:14\n",
            "Running for: 1:12:33.405318\n",
            "DELETE THIS EVERY 75 seconds, this text is here just to block A100\n",
            "Current time: 2024-05-14 17:17:29\n",
            "Running for: 1:13:48.467795\n",
            "Stopped by user.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_U8Q_zNNgJ_D"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "51a10bf4aac848dab612b7f2da457373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_66d0764feee2449a983bb8b7ec57c1e0",
              "IPY_MODEL_0b59cce91a264701aed31033bb9dc4f6",
              "IPY_MODEL_5ef490c3108a4b75867ff9c3c8a30105"
            ],
            "layout": "IPY_MODEL_585d1fc3930f4b14ab30e819cba050d3"
          }
        },
        "66d0764feee2449a983bb8b7ec57c1e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bb3f6852f8c4b179e36a551ea8f4c93",
            "placeholder": "​",
            "style": "IPY_MODEL_afa96929da884ed2bc0146921147de5b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0b59cce91a264701aed31033bb9dc4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e554f6b0e884b369eac70a8d1640c06",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bea00ce11c8f445b84a22df760ea79ec",
            "value": 19
          }
        },
        "5ef490c3108a4b75867ff9c3c8a30105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9931f22f4c5c4cf0b7cf8fb2386ed8c7",
            "placeholder": "​",
            "style": "IPY_MODEL_e7816d2bf05e4c429eb8c430e232311f",
            "value": " 19/19 [03:56&lt;00:00, 21.44s/it]"
          }
        },
        "585d1fc3930f4b14ab30e819cba050d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bb3f6852f8c4b179e36a551ea8f4c93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa96929da884ed2bc0146921147de5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e554f6b0e884b369eac70a8d1640c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea00ce11c8f445b84a22df760ea79ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9931f22f4c5c4cf0b7cf8fb2386ed8c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7816d2bf05e4c429eb8c430e232311f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}