{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfuVf2cH9OEF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from dask.distributed import Client\n",
        "from google.colab import drive\n",
        "\n",
        "# Initialize the Dask Client\n",
        "client = Client()\n",
        "\n",
        "# Mount Google Drive to access the Parquet file\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to the normalized Parquet file on Google Drive\n",
        "input_path = '/content/drive/My Drive/BB_Normalized_Monthly_Final/combined_data_minus_183.parquet'\n",
        "\n",
        "# Load the data using Dask\n",
        "data = dd.read_parquet(input_path)\n",
        "\n",
        "# Compute the total number of rows to determine split points\n",
        "total_rows = len(data)\n",
        "chunk_size = total_rows // 3\n",
        "\n",
        "# Define chunk indices\n",
        "indices = [0, chunk_size, 2 * chunk_size, total_rows]  # ensure the last chunk captures all remaining data\n",
        "\n",
        "# Save each chunk as a separate Parquet file\n",
        "for i in range(3):\n",
        "    chunk = data.partitions[i].compute()  # Compute only the current partition\n",
        "    output_path = f'/content/drive/My Drive/BB_Normalized_Monthly_Final/combined_data_minus_183_part_{chr(65+i)}.parquet'  # A, B, C\n",
        "    chunk.to_parquet(output_path)\n",
        "    print(f\"Chunk {chr(65+i)} saved to {output_path}\")\n",
        "\n",
        "# Clean up resources to free memory\n",
        "client.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqEfjwoT9ZA9",
        "outputId": "cb8290e1-e2ef-4f7f-b5ed-3d883564fc94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
            "INFO:distributed.scheduler:State start\n",
            "INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:35381\n",
            "INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:40195'\n",
            "INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:38509'\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:37337', name: 0, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37337\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44838\n",
            "INFO:distributed.scheduler:Register worker <WorkerState 'tcp://127.0.0.1:33857', name: 1, status: init, memory: 0, processing: 0>\n",
            "INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33857\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44850\n",
            "INFO:distributed.scheduler:Receive client connection: Client-cb1ef2c8-1173-11ef-823f-0242ac1c000c\n",
            "INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44852\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Chunk A saved to /content/drive/My Drive/BB_Normalized_Monthly_Final/combined_data_minus_183_part_A.parquet\n",
            "Chunk B saved to /content/drive/My Drive/BB_Normalized_Monthly_Final/combined_data_minus_183_part_B.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:40195'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.nanny:Closing Nanny at 'tcp://127.0.0.1:38509'. Reason: nanny-close\n",
            "INFO:distributed.nanny:Nanny asking worker to close. Reason: nanny-close\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:44838; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:37337', name: 0, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1715637522.1975114')\n",
            "INFO:distributed.core:Received 'close-stream' from tcp://127.0.0.1:44850; closing.\n",
            "INFO:distributed.scheduler:Remove worker <WorkerState 'tcp://127.0.0.1:33857', name: 1, status: closing, memory: 0, processing: 0> (stimulus_id='handle-worker-cleanup-1715637522.2042723')\n",
            "INFO:distributed.scheduler:Lost all workers\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk C saved to /content/drive/My Drive/BB_Normalized_Monthly_Final/combined_data_minus_183_part_C.parquet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:distributed.scheduler:Scheduler closing due to unknown reason...\n",
            "INFO:distributed.scheduler:Scheduler closing all comms\n"
          ]
        }
      ]
    }
  ]
}